# PaperMapper ‚Äî 10‚Äì12 Hour Build Plan (Claude 3.5 + V0 Frontend)

**Goal:**  
Build a web app that automatically fetches recent **arXiv papers** by topic, clusters them by theme, and generates a **spoken weekly digest** using **Claude 3.5 Sonnet**.

---

## Tech Stack Overview

| Layer | Tool | Purpose |
|-------|------|----------|
| **Frontend** | **V0 by Vercel (Next.js + Tailwind)** | Rapid, elegant UI generation |
| **Backend** | **FastAPI + Uvicorn** | Lightweight API layer |
| **Database** | **SQLite** | Store papers, digests, cached outputs |
| **Embeddings** | `sentence-transformers` **all-MiniLM-L6-v2** | Local, fast embeddings |
| **Vector Index** | **FAISS** (in-process) | Paper clustering |
| **LLM** | **Claude 3.5 Sonnet (API)** | Summaries + digest writing |
| **TTS (optional)** | **ElevenLabs** or **Piper** | Spoken digest |
| **Deployment** | **Vercel (frontend)** + local/Render backend | Simple hosting |

---

## System Architecture (Simplified)

```
arXiv API ‚Üí Embedding (MiniLM) ‚Üí FAISS ‚Üí Clustering (KMeans)
       ‚Üì                                 ‚Üì
    SQLite ‚Üê Claude 3.5 Sonnet ‚Üê FastAPI ‚Üí Frontend (V0)
       ‚Üì
  Optional TTS ‚Üí Audio digest (MP3)
```

---

## API Contracts

### `/api/digest/generate`  
**POST body:**
```json
{ "topic": "diffusion models", "days": 7 }
```

**Response:**
```json
{
  "digestId": "dg_123",
  "summary": "This week in diffusion models...",
  "clusters": [
    {
      "label": "Efficient Training",
      "bullets": ["LoRA variants reduce memory", "New gradient scaling methods"],
      "papers": [
        { "id": "2501.12345", "title": "Improving Diffusion...", "url": "https://arxiv.org/abs/2501.12345" }
      ]
    }
  ],
  "audioUrl": "https://.../dg_123.mp3"
}
```

### `/api/digest/latest?topic=...`  
Returns the latest cached digest.

---

## 10‚Äì12 Hour Timeline (Detailed)

### **Hour 0‚Äì2: Setup & Mock Stage**
**Goal:** Have a working skeleton with mock data visible in the browser.

#### Tasks
- **Frontend (V0):**
  - Scaffold `/papermapper` with:
    - Topic input bar + day selector  
    - ‚ÄúGenerate Digest‚Äù button  
    - Cluster card layout (label, bullets, paper links)
  - Include placeholders and loading states.

- **Backend (FastAPI):**
  - Create `/api/digest/generate` returning static mock JSON.
  - Verify CORS works with local Next.js.

#### Milestone
Clicking **Generate Digest** shows mock clusters on the screen.

---

### **Hour 2‚Äì4: Data Ingestion + Storage**
**Goal:** Pull real arXiv data and store it.

#### Tasks
- Use `python-arxiv` or simple `requests` to fetch:
  ```python
  import arxiv
  search = arxiv.Search(query=topic, max_results=50, sort_by=arxiv.SortCriterion.SubmittedDate)
  ```
- Parse and normalize:
  - `id`, `title`, `abstract`, `authors`, `url`, `published_at`
- Store in **SQLite** table:
  ```sql
  CREATE TABLE papers (
      id TEXT PRIMARY KEY,
      title TEXT,
      abstract TEXT,
      url TEXT,
      published_at TEXT
  );
  ```
- Dedup by title hash.

#### Milestone
Database fills with ~50‚Äì100 papers per topic.

---

### **Hour 4‚Äì6: Embedding + Clustering**
**Goal:** Create groups of related papers.

#### Tasks
- Use MiniLM to embed abstracts:
  ```python
  from sentence_transformers import SentenceTransformer
  model = SentenceTransformer('all-MiniLM-L6-v2')
  embeddings = model.encode(paper_abstracts)
  ```
- Build **FAISS** index:
  ```python
  import faiss
  index = faiss.IndexFlatL2(embeddings.shape[1])
  index.add(embeddings)
  ```
- Run **KMeans (k=6)** clustering:
  ```python
  from sklearn.cluster import KMeans
  km = KMeans(n_clusters=6, random_state=42)
  clusters = km.fit_predict(embeddings)
  ```
- For each cluster:
  - Pick top 3 papers closest to centroid.
  - Save `{cluster_id, title, abstract, url}`.

#### Milestone
Real clusters with top 3 papers each (labels TBD).

---

### **Hour 6‚Äì8: Claude Summaries + Digest**
**Goal:** Replace placeholder labels/bullets with real summaries.

#### Tasks
- Use **Claude 3.5 Sonnet** for:
  - **Cluster labeling & bullets**
  - **Weekly digest composition**

**Cluster Prompt:**
```
You are an academic editor. For EACH cluster, return compact JSON:
{ "label":"<‚â§5 words>",
  "bullets":["<‚â§12 words>","<‚â§12 words>","<‚â§12 words>"],
  "topPapers":[{"title":"...","why":"<‚â§12 words>"}] }
Use only the provided titles/abstract snippets. Be factual, no hype.
```

**Digest Prompt:**
```
Write a weekly digest for "{topic}" in ‚â§450 tokens:
1) One-paragraph overview (what changed this week)
2) 4‚Äì6 sections titled by cluster labels, each with 2 concise bullets
3) End with "What to watch next" (3 bullets)
Return plain text.
```

#### Tasks (continued)
- Batch 2 clusters per call to reduce latency/cost.
- Add JSON validation & retry logic.
- Save results to SQLite:
  ```sql
  CREATE TABLE digests (
      digest_id TEXT PRIMARY KEY,
      topic TEXT,
      summary TEXT,
      clusters_json TEXT,
      created_at TEXT
  );
  ```

#### Milestone
Each cluster has a meaningful label and summary; digest text generated.

---

### **Hour 8‚Äì10: Frontend Integration + Polishing**
**Goal:** Connect everything, make it feel smooth and finished.

#### Tasks
- Hook V0 frontend ‚Üí `/api/digest/generate`
- Show:
  - Cluster label + bullets
  - Top papers as links
  - Digest text below clusters
- Add:
  - Loading skeletons (`isLoading` state)
  - Error toasts
  - Empty-state message (‚ÄúNo papers found‚Äù)

- Polish styling:
  - Large readable fonts
  - Card shadows
  - Color-coded clusters

#### Milestone
Full round trip: **type topic ‚Üí Generate ‚Üí clusters + digest render.**

---

### **Hour 10‚Äì12: Extras + Demo Polish**
**Goal:** Add finishing touches and optional features.

#### Optional Add-Ons
1. **TTS (Spoken Digest):**
   - Use ElevenLabs or Piper for `/api/tts`
   - Play audio via `<audio>` element in UI.
2. **Caching:**
   - Cache digests by `(topic,days)` for 12‚Äì24 hours.
   - If cached, skip LLM call.
3. **Chat About Papers (stretch goal):**
   - Retrieve top-k papers from FAISS ‚Üí send to Claude ‚Üí return grounded answer.
4. **Hotness Score:**
   - Add simple metric: `score = recency + cluster_size`.

#### Demo Prep
- Test 2 topics: `"diffusion models"` and `"LLM safety"`.
- Record short walkthrough.
- 60‚Äì90 sec live demo script:
  ```
  1. Enter topic "LLM safety"
  2. Click Generate
  3. See themed clusters + summaries
  4. Play 2-min audio digest
  5. Copy share link for others
  ```

#### Milestone
Fully polished, demo-ready PaperMapper.

---

## üë• Team Roles

| Role | Responsibilities |
|------|------------------|
| **P1 ‚Äì Backend Lead** | FastAPI setup, Claude integration, caching, TTS endpoint |
| **P2 ‚Äì Frontend (V0)** | Page scaffolding, styling, fetch logic, loading states |
| **P3 ‚Äì Data / ML** | arXiv ingest, embeddings, FAISS, clustering |
| **P4 ‚Äì QA / Integrator** | Testing, validation, debugging, polish |

---

## ‚öôÔ∏è Guardrails & Configs

- **Claude Settings:**
  - `temperature = 0.4`
  - `max_tokens = 400‚Äì600`
  - `model = claude-3.5-sonnet`
- **Error handling:** Retry once on invalid JSON.
- **Caching:** Save digest JSON by `(topic, days)` in SQLite.
- **Security:** Keep Claude API key server-side only.
- **Performance:** Cap abstracts to 3 per cluster to limit context.

---

## Final Deliverables

| Deliverable | Description |
|--------------|-------------|
| **Frontend (V0)** | `/papermapper` page with input, clusters, digest, and player |
| **Backend (FastAPI)** | `/api/digest/generate` connected to Claude |
| **SQLite DB** | Stores cached papers and digests |
| **Claude Summaries** | Cluster labels, bullets, and digest |
| **Audio Digest (optional)** | 2‚Äì3 minute spoken summary |
| **Demo Video** | 1-minute screen recording of working app |

---

## What ‚ÄúDone‚Äù Looks Like

- User enters topic ‚Üí clicks **Generate Digest**  
- App fetches arXiv papers ‚Üí clusters ‚Üí uses Claude ‚Üí shows labeled clusters  
- Digest paragraph + top papers displayed beautifully  
- Audio digest plays smoothly  
- Cached results load instantly next time  

**Result:**  
A polished, research-focused, open-source, LLM-powered tool that looks clean, sounds professional, and *actually solves a real problem*.

---

## Example Directory Layout

```
papermapper/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îú‚îÄ‚îÄ arxiv_ingest.py
‚îÇ   ‚îú‚îÄ‚îÄ clustering.py
‚îÇ   ‚îú‚îÄ‚îÄ claude_client.py
‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îî‚îÄ‚îÄ tts.py
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ papermapper/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ page.tsx
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ components/
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ TopicBar.tsx
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ ClusterCard.tsx
‚îÇ   ‚îÇ           ‚îú‚îÄ‚îÄ DigestPlayer.tsx
‚îÇ   ‚îÇ           ‚îî‚îÄ‚îÄ LoadingSkeleton.tsx
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ papers.db
‚îÇ   ‚îî‚îÄ‚îÄ digests/
‚îÇ       ‚îî‚îÄ‚îÄ *.json
‚îî‚îÄ‚îÄ README.md
```

---

## Bonus Ideas (If Time Permits)
- Add **search bar** for past digests (`/digest/[id]` route)
- **Email weekly digest** to yourself via cron (APScheduler)
- Display **graph of clusters** using `Plotly` or `recharts`
- Add ‚Äú**Eco mode**‚Äù: mini multi-agent debate ranking clusters by importance

---

## Pitch Summary (For Judges)
> ‚ÄúWe built **PaperMapper**, an open-source research companion that turns an entire week of new arXiv papers into a 2-minute digest.  
> It fetches, clusters, summarizes, and even reads the results aloud.  
> Powered by Claude 3.5 and a local FAISS + MiniLM pipeline ‚Äî all open, fast, and focused on saving researchers time.‚Äù

---
